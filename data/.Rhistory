coef_ridge_cv_std[order(abs(-coef_ridge_cv_std$Estimate)),]
coef_ridge_cv_std[order(-abs(coef_ridge_cv_std$Estimate)),]
coef_ridge_cv_std<-coef_ridge_cv_std[order(-abs(coef_ridge_cv_std$Estimate)),]
boot_ridge_CI_coef<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/boot_ridge_CI_coef.csv", colClasses = "character")
boot_ridge_CI_coef<-as.data.frame(t(boot_ridge_CI_coef))
boot_ridge_CI_coef$V1<-round(as.numeric(as.character(boot_ridge_CI_coef$V1)),4)
boot_ridge_CI_coef$V2<-round(as.numeric(as.character(boot_ridge_CI_coef$V2)),4)
names <- rownames(boot_ridge_CI_coef)
rownames(boot_ridge_CI_coef) <- NULL
boot_ridge_CI_coef <- cbind(names,boot_ridge_CI_coef)
colnames(boot_ridge_CI_coef)<-c("Predictor", "2.5%", "97.5%")
boot_ridge_CI_coef$Predictor<-as.character(boot_ridge_CI_coef$Predictor)
boot_ridge_CI_coef$Predictor[which(boot_ridge_CI_coef$Predictor=="X.Intercept.")]<-"(Intercept)"
coef_ridge_cv_std
coef_ridge<-merge(coef_ridge_cv_std, boot_ridge_CI_coef, by="Predictor")
coef_ridge
coef_ridge
coef_ridge[order(abs(coef_ridge$Estimate)),]
coef_ridge[order(-abs(coef_ridge$Estimate)),]
coef_ridge<-coef_ridge[order(-abs(coef_ridge$Estimate)),]
boot_elastic_usage<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/boot_elastic_usage.csv")
colnames(boot_elastic_usage)<-c("Predictor", "Percentage Used")
boot_elastic_usage
-boot_elastic_usage[order(boot_elastic_usage$`Percentage Used`)]
boot_elastic_usage<-boot_elastic_usage[order(boot_elastic_usage$'Percentage Used')]
boot_elastic_usage<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/boot_elastic_usage.csv")
boot_elastic_usage
boot_elastic_usage[order(boot_elastic_usage$boot_elastic_usage),]
boot_elastic_usage[order(-boot_elastic_usage$boot_elastic_usage),]
boot_elastic_usage<-boot_elastic_usage[order(-boot_elastic_usage$boot_elastic_usage),]
colnames(boot_elastic_usage)<-c("Predictor", "Percentage Used")
boot_lasso_usage<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/boot_lasso_usage.csv")
boot_lasso_usage
boot_lasso_usage<-boot_lasso_usage[order(-boot_lasso_usage$boot_lasso_usage),]
colnames(boot_lasso_usage)<-c("Predictor", "Percentage Used")
#clean environment
rm(list=ls())
library(stringr)
library(stringr)
library(ggplot2)
library(stringr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(cowplot)
library(corrplot)
library(factoextra)
library(grid)
library(GGally)
library(cowplot)
library(corrplot)
library(factoextra)
library(grid)
library(reshape)
library(reshape)
library(psych)
library(reshape)
library(psych)
library(knitr)
library(GGally)
library(cowplot)
library(corrplot)
library(factoextra)
library(grid)
library(reshape)
library(psych)
library(knitr)
library(kableExtra)
library(tidyr)
library(glmnet)
#load data
prof_data<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/imbalanced_train.csv", colClasses = "character")
names(prof_data)
prof_data$ENTITY_CD[which(prof_data$CHARTER==1)]
prof_data<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/prof_data.csv", colClasses = "character")
prof_data<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/proficiency_data.csv", colClasses = "character")
nrow(prof_data)
length(which(prof_data$PROF_LEVEL=="Proficient"))
length(which(prof_data$PROF_LEVEL=="not Proficient"))
length(which(prof_data$PROF_LEVEL=="Not Proficient"))
3050+277
277/3327
#clean environment
rm(list=ls())
#load data
prof_data<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/imbalanced_train.csv", colClasses = "character")
nrow(prof_data)
#set working directory
setwd("~/Desktop/summer_projects/NY_school_performance/data")
#load data
train<-read.csv("imbalanced_train.csv", colClasses = "character")
test<-read.csv("test.csv", colClasses = "character")
#clean environment
rm(list=ls())
#libraries
library(dplyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(cowplot)
library(corrplot)
library(factoextra)
library(tidyr)
library(broom)
library(glmnet)
library(plotmo)
library(caret)
library(bootstrap)
library(stargazer)
library(knitr)
library(kableExtra)
#set working directory
setwd("~/Desktop/summer_projects/NY_school_performance/data")
#load data
train<-read.csv("imbalanced_train.csv", colClasses = "character")
test<-read.csv("test.csv", colClasses = "character")
#make columns into numeric
train[,6:30]<-sapply(train[,6:30], as.numeric)
test[,6:30]<-sapply(test[,6:30], as.numeric)
train$CHARTER<-as.factor(train$CHARTER)
test$CHARTER<-as.factor(test$CHARTER)
#response as factor
train$PROF_LEVEL<-as.factor(train$PROF_LEVEL)
test$PROF_LEVEL<-as.factor(test$PROF_LEVEL)
#drop other variables
train$ENTITY_CD<-NULL
train$ENTITY_NAME <-NULL
train$DISTRICT_NAME<-NULL
train$COUNTY_NAME<-NULL
test$ENTITY_CD<-NULL
test$ENTITY_NAME <-NULL
test$DISTRICT_NAME<-NULL
test$COUNTY_NAME<-NULL
train[,2:22]<-scale(train[,2:22])
train[,24:26]<-scale(train[,24:26])
test[,2:22]<-scale(test[,2:22])
test[,24:26]<-scale(test[,24:26])
# separate predictors and response variable for glmnet
predictors<-data.matrix(train[,2:26])
proficiency_level<-as.factor(train[,1])
######################################
#LOGISTIC SCALED SELECTED VARIABLES
######################################
logistic_selected <- glm(PROF_LEVEL ~ PER_BLACK + PER_HISP+ PER_ASIAN + PER_WHITE +
PER_ECDIS + PER_SUSPENSIONS+ MEAN_INC+ EXP_PER_ST+
PROP_CRIME_PER_CITIZEN+ TOTAL_DIST_POP + CHARTER,
data = train, family = "binomial")
##############################
# Ridge regression
###############################
#lambda cross-validation
set.seed(100)
ridge_cv_std <- cv.glmnet(predictors, proficiency_level,
type.measure="class", nfolds=20,
family="binomial", alpha=0)
#####################################
# Elastic Net regression
#####################################
cv_alpha<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/cv_alpha.csv", colClasses = "numeric")
cv_alpha<-cv_alpha[1,]
#lambda cross-validation
set.seed(100)
elastic_cv_std <- cv.glmnet(predictors, proficiency_level,
type.measure="class", nfolds=20,
family="binomial", alpha=cv_alpha)
##############################
# LASSO Regression
##############################
#lambda cross-validation
set.seed(100)
lasso_cv_std <- cv.glmnet(predictors, proficiency_level,
type.measure="class", nfolds=20,
family="binomial", alpha=1)
elastic_cv_std$lambda.min
ridge_cv_std$lambda.1se
log(elastic_cv_std$lambda.min)
ridge_cv_std$cvm[ridge_cv_std$lambda == ridge_cv_std$lambda.min]
log(ridge_cv_std$lambda.min)
ridge_cv_std$cvm[ridge_cv_std$lambda == ridge_cv_std$lambda.1se]
elastic_cv_std$cvm[elastic_cv_std$lambda == elastic_cv_std$lambda.min]
log(elastic_cv_std$lambda.min)
coef(elastic_cv_std, "lambda.min")
elastic_cv_std$lambda.1se
elastic_cv_std$cvm[elastic_cv_std$lambda == elastic_cv_std$lambda.1se]
log(elastic_cv_std$lambda.1se)
coef(elastic_cv_std, "lambda.1se")
lasso_cv_std$cvm[lasso_cv_std$lambda == lasso_cv_std$lambda.min]
log(lasso_cv_std$lambda.min)
coef(lasso_cv_std,"lambda.min")
lasso_cv_std$cvm[lasso_cv_std$lambda == lasso_cv_std$lambda.1se]
log(lasso_cv_std$lambda.1se)
coef(lasso_cv_std,"lambda.1se")
#clean environment
rm(list=ls())
#libraries
library(dplyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(cowplot)
library(corrplot)
library(factoextra)
library(tidyr)
library(broom)
library(glmnet)
library(plotmo)
library(caret)
library(bootstrap)
library(stargazer)
library(knitr)
library(kableExtra)
#set working directory
setwd("~/Desktop/summer_projects/NY_school_performance/data")
#load data
train<-read.csv("imbalanced_train.csv", colClasses = "character")
test<-read.csv("test.csv", colClasses = "character")
#make columns into numeric
train[,6:30]<-sapply(train[,6:30], as.numeric)
test[,6:30]<-sapply(test[,6:30], as.numeric)
train$CHARTER<-as.factor(train$CHARTER)
test$CHARTER<-as.factor(test$CHARTER)
#response as factor
train$PROF_LEVEL<-as.factor(train$PROF_LEVEL)
test$PROF_LEVEL<-as.factor(test$PROF_LEVEL)
#drop other variables
train$ENTITY_CD<-NULL
train$ENTITY_NAME <-NULL
train$DISTRICT_NAME<-NULL
train$COUNTY_NAME<-NULL
test$ENTITY_CD<-NULL
test$ENTITY_NAME <-NULL
test$DISTRICT_NAME<-NULL
test$COUNTY_NAME<-NULL
train[,2:22]<-scale(train[,2:22])
train[,24:26]<-scale(train[,24:26])
test[,2:22]<-scale(test[,2:22])
test[,24:26]<-scale(test[,24:26])
# separate predictors and response variable for glmnet
predictors<-data.matrix(train[,2:26])
proficiency_level<-as.factor(train[,1])
######################################
#LOGISTIC SCALED SELECTED VARIABLES
######################################
logistic_selected <- glm(PROF_LEVEL ~ PER_BLACK + PER_HISP+ PER_ASIAN + PER_WHITE +
PER_ECDIS + PER_SUSPENSIONS+ MEAN_INC+ EXP_PER_ST+
PROP_CRIME_PER_CITIZEN+ TOTAL_DIST_POP + CHARTER,
data = train, family = "binomial")
##############################
# Ridge regression
###############################
#lambda cross-validation
set.seed(100)
ridge_cv_std <- cv.glmnet(predictors, proficiency_level,
type.measure="class", nfolds=20,
family="binomial", alpha=0)
#####################################
# Elastic Net regression
#####################################
cv_alpha<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/cv_alpha.csv", colClasses = "numeric")
cv_alpha<-cv_alpha[1,]
#lambda cross-validation
set.seed(100)
elastic_cv_std <- cv.glmnet(predictors, proficiency_level,
type.measure="class", nfolds=20,
family="binomial", alpha=cv_alpha)
##############################
# LASSO Regression
##############################
#lambda cross-validation
set.seed(100)
lasso_cv_std <- cv.glmnet(predictors, proficiency_level,
type.measure="class", nfolds=20,
family="binomial", alpha=1)
par(mfrow=c(1,3), mar = c(5,4,5.5,2) + 0.1)
plot(ridge_cv_std, main="Ridge",  pch = 10, cex = .5, font.main=1)
plot(elastic_cv_std, main="Elastic Net", pch = 10, cex = .5,font.main=1)
plot(lasso_cv_std, main="LASSO", pch = 10, cex = .5,font.main=1)
#run models
ridge_model <- glmnet(predictors,proficiency_level, family="binomial", alpha=0)
elastic_model <- glmnet(predictors, proficiency_level, family="binomial", alpha=cv_alpha)
lasso_model <- glmnet(predictors, proficiency_level, family="binomial", alpha=1)
par(mfrow=c(1,3), mar = c(5,4,5.5,2) + 0.1)
plot_glmnet(ridge_model, label=10, main="Ridge", cex.main=2)
plot_glmnet(elastic_model, label=10, main="Elastic Net", cex.main=2)
plot_glmnet(lasso_model, label=10, main="LASSO",cex.main=2)
#coefficients at min lambda and within one standard deviation
coef_ridge_cv_std<-as.data.frame(as.matrix(coef(ridge_cv_std, s= "lambda.1se")))
names <- rownames(coef_ridge_cv_std)
rownames(coef_ridge_cv_std) <- NULL
coef_ridge_cv_std <- cbind(names,coef_ridge_cv_std)
colnames(coef_ridge_cv_std)<-c("Predictor", "Estimate")
coef_ridge_cv_std$Estimate<-round(as.numeric(coef_ridge_cv_std$Estimate),4)
boot_ridge_CI_coef<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/boot_ridge_CI_coef.csv", colClasses = "character")
boot_ridge_CI_coef<-as.data.frame(t(boot_ridge_CI_coef))
boot_ridge_CI_coef$V1<-round(as.numeric(as.character(boot_ridge_CI_coef$V1)),4)
boot_ridge_CI_coef$V2<-round(as.numeric(as.character(boot_ridge_CI_coef$V2)),4)
names <- rownames(boot_ridge_CI_coef)
rownames(boot_ridge_CI_coef) <- NULL
boot_ridge_CI_coef <- cbind(names,boot_ridge_CI_coef)
colnames(boot_ridge_CI_coef)<-c("Predictor", "2.5%", "97.5%")
boot_ridge_CI_coef$Predictor<-as.character(boot_ridge_CI_coef$Predictor)
boot_ridge_CI_coef$Predictor[which(boot_ridge_CI_coef$Predictor=="X.Intercept.")]<-"(Intercept)"
coef_ridge<-merge(coef_ridge_cv_std, boot_ridge_CI_coef, by="Predictor")
coef_ridge<-coef_ridge[order(-abs(coef_ridge$Estimate)),]
#ELASTIC coefficients at min lambda and within one standard deviation
coef_elastic_cv_std<-as.data.frame(as.matrix(coef(elastic_cv_std, s= "lambda.1se")))
names <- rownames(coef_elastic_cv_std)
rownames(coef_elastic_cv_std) <- NULL
coef_elastic_cv_std <- cbind(names,coef_elastic_cv_std)
colnames(coef_elastic_cv_std)<-c("Predictor", "Estimate")
coef_elastic_cv_std$Estimate<-round(as.numeric(coef_elastic_cv_std$Estimate),4)
boot_elastic_CI_coef<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/boot_elastic_CI_coef.csv", colClasses = "character")
boot_elastic_CI_coef<-as.data.frame(t(boot_elastic_CI_coef))
boot_elastic_CI_coef$V1<-round(as.numeric(as.character(boot_elastic_CI_coef$V1)),4)
boot_elastic_CI_coef$V2<-round(as.numeric(as.character(boot_elastic_CI_coef$V2)),4)
names <- rownames(boot_elastic_CI_coef)
rownames(boot_elastic_CI_coef) <- NULL
boot_elastic_CI_coef <- cbind(names,boot_elastic_CI_coef)
colnames(boot_elastic_CI_coef)<-c("Predictor", "2.5%", "97.5%")
boot_elastic_CI_coef$Predictor<-as.character(boot_elastic_CI_coef$Predictor)
boot_elastic_CI_coef$Predictor[which(boot_elastic_CI_coef$Predictor=="X.Intercept.")]<-"(Intercept)"
coef_elastic<-merge(coef_elastic_cv_std, boot_elastic_CI_coef, by="Predictor")
coef_elastic[is.na(coef_elastic)]<-0
coef_elastic<-coef_elastic[order(-abs(coef_elastic$Estimate)),]
#LASSO coefficients at min lambda and within one standard deviation
coef_lasso_cv_std<-as.data.frame(as.matrix(coef(lasso_cv_std, s= "lambda.1se")))
names <- rownames(coef_lasso_cv_std)
rownames(coef_lasso_cv_std) <- NULL
coef_lasso_cv_std <- cbind(names,coef_lasso_cv_std)
colnames(coef_lasso_cv_std)<-c("Predictor", "Estimate")
coef_lasso_cv_std$Estimate<-round(as.numeric(coef_lasso_cv_std$Estimate),4)
boot_lasso_CI_coef<-read.csv("~/Desktop/summer_projects/NY_school_performance/data/boot_lasso_CI_coef.csv", colClasses = "character")
boot_lasso_CI_coef<-as.data.frame(t(boot_lasso_CI_coef))
boot_lasso_CI_coef$V1<-round(as.numeric(as.character(boot_lasso_CI_coef$V1)),4)
boot_lasso_CI_coef$V2<-round(as.numeric(as.character(boot_lasso_CI_coef$V2)),4)
names <- rownames(boot_lasso_CI_coef)
rownames(boot_lasso_CI_coef) <- NULL
boot_lasso_CI_coef <- cbind(names,boot_lasso_CI_coef)
colnames(boot_lasso_CI_coef)<-c("Predictor", "2.5%", "97.5%")
boot_lasso_CI_coef$Predictor<-as.character(boot_lasso_CI_coef$Predictor)
boot_lasso_CI_coef$Predictor[which(boot_lasso_CI_coef$Predictor=="X.Intercept.")]<-"(Intercept)"
coef_lasso<-merge(coef_lasso_cv_std, boot_lasso_CI_coef, by="Predictor")
coef_lasso[is.na(coef_lasso)]<-0
coef_lasso<-coef_lasso[order(-abs(coef_lasso$Estimate)),]
kable(coef_ridge, caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression")[1:10] %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
kable(coef_ridge, caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression") %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
kable(coef_ridge, caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression")[1:10,] %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
kable(coef_ridge, caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression")[1:10]
kable(coef_ridge, caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression")[1:10] %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
kable(coef_ridge, caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression") %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
kable(coef_ridge[1:10], caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression") %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
coef_ridge
kable(coef_ridge[1:10,], caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression") %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
coef_ridge
class(coef_ridge)
View(coef_ridge)
kable(coef_ridge[1:10,], caption="Coefficient Estimates and 95\\% Bootstrap CI on Ridge Regression", row.names = F) %>%
kable_styling(font_size = 7, latex_options = "HOLD_position")
######################################
# TASK: Logistic Regression Analysis #
######################################
#clean environment
rm(list=ls())
#libraries
library(dplyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(cowplot)
library(corrplot)
library(factoextra)
library(tidyr)
library(broom)
library(glmnet)
library(plotmo)
library(caret)
library(bootstrap)
#set working directory
setwd("~/Desktop/summer_projects/NY_school_performance/data")
#load data
train<-read.csv("imbalanced_train.csv", colClasses = "character")
test<-read.csv("test.csv", colClasses = "character")
#make columns into numeric
train[,6:30]<-sapply(train[,6:30], as.numeric)
test[,6:30]<-sapply(test[,6:30], as.numeric)
train$CHARTER<-as.factor(train$CHARTER)
test$CHARTER<-as.factor(test$CHARTER)
#response as factor
train$PROF_LEVEL<-as.factor(train$PROF_LEVEL)
test$PROF_LEVEL<-as.factor(test$PROF_LEVEL)
#drop other variables
train$ENTITY_CD<-NULL
train$ENTITY_NAME <-NULL
train$DISTRICT_NAME<-NULL
train$COUNTY_NAME<-NULL
test$ENTITY_CD<-NULL
test$ENTITY_NAME <-NULL
test$DISTRICT_NAME<-NULL
test$COUNTY_NAME<-NULL
######################################
#LOGISTIC SCALED ALL VARIABLES
######################################
train[,2:22]<-scale(train[,2:22])
train[,24:26]<-scale(train[,24:26])
test[,2:22]<-scale(test[,2:22])
test[,24:26]<-scale(test[,24:26])
logistic_all <- glm(PROF_LEVEL ~ . , data = train, family = "binomial")
# CHECK ASSUMPTTIONS
# Lineartiy: perceived non-linearity due to  outliers
probabilities <- predict(logistic_all, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "Proficient", "Not Proficient")
predictors<-names(train)[which(names(train)!="PROF_LEVEL")]
linearity<-
train[,2:22] %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(linearity, aes(logit, predictor.value))+
geom_point(size = 0.2, alpha = 0.2) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
#Influential points: A few influential points
plot(logistic_all, which = 4, id.n = 3)
model.data <-
augment(logistic_all) %>%
mutate(index = 1:n())
model.data%>%
top_n(3, .cooksd)
#Outliers: A few infuential points
ggplot(model.data, aes(index, .std.resid)) +
geom_point(aes(color = PROF_LEVEL), alpha = .5, size=.5) +
theme_bw()
outliers<-
model.data %>%
filter(abs(.std.resid) > 3)
# Results of Logistic model using data without outliers.
no_out_train<-train[-(outliers$index),]
no_out_logistic_all <- glm(PROF_LEVEL ~ . , data = no_out_train, family = "binomial")
summary(no_out_logistic_all)
#Pseudo-Rsquared
1-(logistic_all$deviance/logistic_all$null.deviance)
#Prediction Accuracy logistic all data points v  data without outliers
predicted.classes <- ifelse(predict(logistic_all, test) > 0.5, "Proficient", "Not Proficient")
predicted.classes_no_out <- ifelse(predict(no_out_logistic_all, test) > 0.5, "Proficient", "Not Proficient")
table(predicted.classes, test$PROF_LEVEL)
table(predicted.classes_no_out, test$PROF_LEVEL)
# Results Logistic scaled
summary(logistic_all)
confint(logistic_all)
confint.default(logistic_all)
exp(cbind(OR = coef(logistic_all), confint(logistic_all)))
with(logistic_all, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
#Pseudo-Rsquared
1-(logistic_all$deviance/logistic_all$null.deviance)
#Prediction Accuracy logistic all data points v  data without outliers
predicted.classes <- ifelse(predict(logistic_all, test) > 0.5, "Proficient", "Not Proficient")
table(predicted.classes, test$PROF_LEVEL)
######################################
#LOGISTIC SCALED SELECTED VARIABLES
######################################
logistic_selected <- glm(PROF_LEVEL ~ PER_BLACK + PER_HISP+ PER_ASIAN + PER_WHITE +
PER_ECDIS + PER_SUSPENSIONS+ MEAN_INC+ EXP_PER_ST+
PROP_CRIME_PER_CITIZEN+ TOTAL_DIST_POP + CHARTER,
data = train, family = "binomial")
summary(logistic_selected)
confint(logistic_selected)
with(logistic_selected, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
#Pseudo-Rsquared
1-(logistic_selected$deviance/logistic_selected$null.deviance)
#Prediction Accuracy logistic all data points v  data without outliers
predicted.classes <- ifelse(predict(logistic_selected, test) > 0.5, "Proficient", "Not Proficient")
table(predicted.classes, test$PROF_LEVEL)
#boot strap prediction accuracy
n<-nrow(train)
B<-1000
boot_accuracy<-list()
for (b in 1:B){
#sample ids
i=sample(1:n, size=n, replace=T)
#extract ids
boot_samp<-train[i,]
#run model
boot_logistic_selected <- glm(PROF_LEVEL ~ PER_BLACK + PER_HISP+ PER_ASIAN + PER_WHITE +
PER_ECDIS + PER_SUSPENSIONS+ MEAN_INC+ EXP_PER_ST+
PROP_CRIME_PER_CITIZEN+ TOTAL_DIST_POP + CHARTER,
data = boot_samp, family = "binomial")
#make prediction using above model
predicted.classes<-ifelse(predict(boot_logistic_selected, test) > 0.5, "Proficient", "Not Proficient")
#create confusion matrix
confusion_matrix<-table(predicted.classes, test$PROF_LEVEL)
#extract overall accuracy and place in list
boot_accuracy[b]<-sum(diag(confusion_matrix))/sum(confusion_matrix)
}
# 95CI% on Prediction Accuracy
boot_accuracy<-unlist(boot_accuracy)
boot_selected_CI_acc<-quantile(boot_accuracy, c(0.025, 0.975))
write.csv(boot_selected_CI_acc, "~/Desktop/summer_projects/NY_school_performance/data/boot_selected_CI_acc.csv", row.names = F)
View(test)
length(which(test$PROF_LEVEL==))
length(which(test$PROF_LEVEL=="Proficient"))
length(which(test$PROF_LEVEL=="Not Proficient"))
names(test)
